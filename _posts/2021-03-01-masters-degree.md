---
layout: post
title: "My Master's Degree: A Random Walk Into the Academics Of AI"
description: ""
thumb_image: "documentation/sample-image.jpg"
tags: [personal-thoughts, machine-learning,]
---

# PROLOGUE
My master's degree has had a significant contribution to understanding the fundamentals of CS and Artificial "Intelligence"(who is "intelligent"?). To give some background, I was building software for 3.5 years at an Adtech startup in India before I took up a master's degree. My main intent of doing a master's degree was to clear my fundamentals and understand this "AI" thing that all the cool kids on the block were talking about.
The idea of this blog post is to combine the experience of the last 6 years to synthesize some learnings and some predictions. All of the learnings and predictions and are aligned towards building software/"ML" and technology. The learnings and predictions have arisen from my insights of reading CS research over the past year and collating it with trends I have seen in the industry/open-source software etc.

# Introduction
The ability to write code in the 21st century is a legit superpower. Many would read this and roll their eyes. But if you think about it, It does kinda make sense. Programming enables you to create what Naval Ravikant calls "Infinite Leverage". It's that one skill through which the impact of one's work can have extremely asymmetric returns. But in the earlier days, there were boundaries to what one can and couldn't do with software. We are slowly approaching a time where that distinction is getting blurrier. Meaning the "superpower" can accommodate more "abilities" and "unlocks" if newer knowledge is acquired. My choice to get a master's degree was purely to open a few of these "unlocks". In the process of acquiring these new skills, I gained a few key learnings that made me ponder up the implications of what I learned. The next sections will discuss exactly these things: The learnings and predictions based on them. Everything thing written here should be taken with a grain of salt. Even though I am really optimistic about "Machine learning" and "Neural networks", I will mention that for many problems neural networks are just brittle/overkill, and there's currently just a gold-rush for publishing in the field so by the time you may be reading this, some ideas here may be outdated. And never forget: **There is no such thing as a free lunch**

<div>
  <iframe src="https://arxiv-miner.com/app/kibana#/visualize/edit/901a3af0-7b8f-11eb-864d-cba5fd5c31fb?embed=true&_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:now-5y,to:'2021-03-31T22:23:16.277Z'))&_a=(filters:!(),linked:!f,query:(language:kuery,query:''),uiState:(vis:(colors:('All%20Papers':%233F6833,'Gaussian%20Techniques':%23508642,'Language%20Models':%239AC48A,'Neural%20Network%20Interpretability':%23447EBC,'Neural%20Networks':%23508642))),vis:(aggs:!((enabled:!t,id:'1',params:(customLabel:'Number%20Of%20Papers%20(%20Log%20Scale%20)%20',json:''),schema:metric,type:count),(enabled:!t,id:'2',params:(customLabel:'Publishing%20Date',drop_partials:!f,extended_bounds:(),field:identity.published,interval:M,min_doc_count:1,scaleMetricValues:!f,timeRange:(from:now-5y,to:now),useNormalizedEsInterval:!t),schema:segment,type:date_histogram),(enabled:!t,id:'3',params:(filters:!((input:(language:kuery,query:'ontology.union.keyword%20:%20reinforcement%20learning'),label:'Reinforcement%20Learning'),(input:(language:kuery,query:'ontology.union.keyword%20:%20%22gan%22%20'),label:GANS),(input:(language:kuery,query:'ontology.union.keyword%20:%20%22game%20theory%22'),label:'Game%20Theory'),(input:(language:kuery,query:'ontology.union.keyword%20:%20%22privacy%22'),label:Privacy),(input:(language:kuery,query:'identity.categories.keyword%20:%22cs.DB%22%20'),label:Database),(input:(language:kuery,query:'ontology.union.keyword%20:%20%22gaussians%22%20'),label:'Gaussian%20Techniques'),(input:(language:kuery,query:'ontology.union.keyword%20:%22encryption%22%20'),label:Encryption),(input:(language:kuery,query:'ontology.union.keyword%20:%22language%20model%22%20'),label:'Language%20Models'),(input:(language:kuery,query:'ontology.union.keyword%20:%22evolutionary%20algorithms%22%20or%20ontology.union.keyword%20:%22genetic%20algorithms%22%20'),label:'Evolutionary%20Algorithms'),(input:(language:kuery,query:'ontology.union.keyword%20:%22data%20augmentation%22%20'),label:'Data%20Augmentation'),(input:(language:kuery,query:'ontology.union.keyword%20:%22neural%20networks%22%20and%20ontology.union.keyword%20:%22interpretability%22%20%20'),label:'Neural%20Network%20Interpretability'),(input:(language:kuery,query:'ontology.union.keyword%20:%22robots%22%20'),label:Robotics),(input:(language:kuery,query:'ontology.union.keyword%20:%22blockchain%22%20'),label:Blockchain),(input:(language:kuery,query:'ontology.union.keyword%20:%20social%20networks'),label:'Social%20Networks'),(input:(language:kuery,query:'ontology.union.keyword%20:%22search%20engines%22'),label:'Search%20Engines'),(input:(language:kuery,query:'ontology.union.keyword%20:%22recommendation%22%20'),label:Recommendations),(input:(language:kuery,query:'Neural%20Networks'),label:''),(input:(language:kuery,query:'_id%20:%20*%20'),label:'All%20Papers'))),schema:group,type:filters)),params:(addLegend:!t,addTimeMarker:!f,addTooltip:!f,categoryAxes:!((id:CategoryAxis-1,labels:(filter:!t,rotate:90,show:!t,truncate:100),position:bottom,scale:(type:linear),show:!t,style:(),title:(),type:category)),grid:(categoryLines:!f,valueAxis:ValueAxis-1),labels:(),legendPosition:top,seriesParams:!((data:(id:'1',label:'Number%20Of%20Papers%20(%20Log%20Scale%20)%20'),drawLinesBetweenPoints:!t,interpolate:cardinal,lineWidth:2,mode:normal,show:!t,showCircles:!t,type:line,valueAxis:ValueAxis-1)),thresholdLine:(color:%23E7664C,show:!f,style:full,value:10,width:1),times:!(),type:line,valueAxes:!((id:ValueAxis-1,labels:(filter:!f,rotate:0,show:!t,truncate:100),name:LeftAxis-1,position:left,scale:(mode:normal,type:log),show:!t,style:(),title:(text:'Number%20Of%20Papers%20(%20Log%20Scale%20)%20'),type:value))),title:'Research%20Topic%20Trend%20Charts',type:line))" height="800" width="1200"></iframe>
</div>

# Learnings

All the "AI" that creates awe has been created in the last decade(Even though conceptualized much earlier). People have been astonished when I tell them that a decade ago a huge number of benchmarks were not even there! It all started in 2012 when a bunch of researchers from Toronto took a decades-old idea and made it work for classifying images. This event "broke computer vision". What I mean by "Breaking computer vision" is that this system was several folds better than existing technology!. It was "State Of the Art"(SOTA). (Nowadays we have a new SOTA every few weeks which makes me ponder on the "State" of SOTA). This is what started the entire gold rush and the fundamental technology(Neural networks) which helped create this system started getting applied to other more harder and challenging problems.

This historical context can be seen best from the below timeline where interesting discoveries/inventions like GANS(Converting images of zebras to horses and horses to zebras) came in 2014 and it all further escalated over the next few years to gameplaying(GO and DOTA 2), language translation, music generation and even writing authentic-looking essays. It's now even helping create "good enough" predictions for folding proteins. This timeline tries to note down some key events which are game-changing "Firsts".

The key insight from this historical context is that the wide-scale usage of this tech is NEW!. It's not as old as the C compiler or the Linux operating system. New insights and ideas are emerging as the technology is democratized via opensource packages!.

My master's degree gave me a lot of time to read research around this topic and synthesize a few "meta" insights I learned about this field

{% include image.html path="documentation/sample-image.jpg"
                      path-detail="documentation/sample-image@2x.jpg"
                      alt="Some Image" %}